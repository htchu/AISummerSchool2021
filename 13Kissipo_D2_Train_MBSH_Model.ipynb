{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Kissipo-D2-Train MBSH Model",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IhUAV_I1bszO"
      },
      "source": [
        "<table width=\"100%\" border=\"3\">\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <td width=120><img src=\"https://is4-ssl.mzstatic.com/image/thumb/Purple128/v4/9f/38/cb/9f38cb51-c606-6fd4-54b3-47bfdb06b712/source/256x256bb.jpg\" alt=\"Aidea\" width=\"120\"/></td>\n",
        "      <td align='left'><h1>TensorFlow 2 Object Detection</h1><BR><h2>D2-Train object detection model for MBSH</h2></td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nE0tqcOKcIFI"
      },
      "source": [
        "\n",
        "# Mosquito Breeding Site Hunting for Dengue Fever Control\n",
        "\n",
        "Dengue fever is an acute infectious disease transmitted by mosquito. The peak time of dengue fever outbreak in Taiwan is usually at summertime. Mild clinical cases of dengue fever may present as symptoms such as fever, headaches, and myalgia while severe cases may have severe fluid leakage, hemorrhagic symptoms, shock, organ failure, coma and even death. The mortality rate can be as high as 20% or more if the patient does not receive proper treatment in time.\n",
        "\n",
        "__IEEE ICIP 2019 Grand Challenge__ https://aidea-web.tw/icip\n",
        "![alt MBSH database](https://aidea-web.tw/images/web/ICIP-2019-LOGO-s.png)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RjoqPgqucTPu"
      },
      "source": [
        "# Part 1: Configure the Colab environment to execute Object Detection API with TensorFlow 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uN0sFtMaMprA"
      },
      "source": [
        "## Step 1: Mount google drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ssXeS_e0Mwiu"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tzDDahszNpFc"
      },
      "source": [
        "## Step 5: Install packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jGVaM0f8N5bh"
      },
      "source": [
        "!pip install tf_slim\n",
        "!pip install lvis\n",
        "!pip install tensorflow-addons"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "80oPSKg_OMEX"
      },
      "source": [
        "## Step 6: Set up the working environment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wvFBNg8TO-xH"
      },
      "source": [
        "%env PYTHONPATH=/env/python:/content/drive/My Drive/models:/content/drive/My Drive/models/research:/content/drive/My Drive/models/research/slim"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BUUyVBCSPDxw"
      },
      "source": [
        "import sys\n",
        "sys.path.append('/content/drive/My Drive/models')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jsTxCICeGK0_"
      },
      "source": [
        "from os import chdir\n",
        "chdir(\"/content/drive/My Drive/models/research/\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Sqr8mC3PG-i"
      },
      "source": [
        "## Step 7: Test Object Detection API\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_uR7Hn2hPO8I"
      },
      "source": [
        "!python object_detection/builders/model_builder_tf2_test.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N5WRaRKIQYFp"
      },
      "source": [
        "# Part 2: (IPO-I) input data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v-P9WQVGQhWk"
      },
      "source": [
        "## Step 1: Create tfrecords folder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I9PIpQ8IQqwk"
      },
      "source": [
        "%%bash\n",
        "cd models/research/\n",
        "mkdir data data/tfrecords"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a9dhP_bgQ6r7"
      },
      "source": [
        "## Step 2: Download data from the cloud drive\n",
        "If the download fails, you can upload it yourself\n",
        "\n",
        "https://drive.google.com/file/d/1_lh-QnjvPc4v9EDhisuwCTVZAUlKE6lR/view?usp=sharing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AkvYvZRShrzU"
      },
      "source": [
        "!gdown --id 1_lh-QnjvPc4v9EDhisuwCTVZAUlKE6lR\n",
        "!unzip mosquito.zip\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vs1xNOoaRTLS"
      },
      "source": [
        "!pwd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OfxmgwUfRvns"
      },
      "source": [
        "!ls *cdc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y1CisvKTSBzd"
      },
      "source": [
        "%%bash\n",
        "mv test_cdc models/research/data\n",
        "mv train_cdc models/research/data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6t40lVwFSTSI"
      },
      "source": [
        "!ls models/research/data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MB37hVb5SZyL"
      },
      "source": [
        "## Step 3: Convert annotations into a csv file\n",
        "\n",
        "https://github.com/EdjeElectronics/TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10/blob/master/xml_to_csv.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h9cc8QLuT9RC"
      },
      "source": [
        "import os\n",
        "import io\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from PIL import Image\n",
        "from object_detection.utils import dataset_util\n",
        "from collections import namedtuple, OrderedDict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gw-WsmBxRx4o"
      },
      "source": [
        "from os import chdir\n",
        "chdir(\"/content/drive/My Drive/models/research/\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2BT1jg10SpwH"
      },
      "source": [
        "!pwd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PUNszJxxaJrq"
      },
      "source": [
        "import os\n",
        "import glob\n",
        "import pandas as pd\n",
        "import xml.etree.ElementTree as ET\n",
        "xml_list = []\n",
        "for xml_file in glob.glob('data/train_cdc/train_annotations/*.xml'):\n",
        "    tree = ET.parse(xml_file)\n",
        "    root = tree.getroot()\n",
        "    for member in root.findall('object'):\n",
        "        value = (root.find('filename').text,\n",
        "                  int(root.find('size')[0].text),\n",
        "                  int(root.find('size')[1].text),\n",
        "                  member[0].text,\n",
        "                  int(member[1][0].text),\n",
        "                  int(member[1][1].text),\n",
        "                  int(member[1][2].text),\n",
        "                  int(member[1][3].text)\n",
        "                  )\n",
        "        xml_list.append(value)\n",
        "\n",
        "column_name = ['filename', 'width', 'height', 'class', 'xmin', 'ymin', 'xmax', 'ymax']\n",
        "xml_df = pd.DataFrame(xml_list, columns=column_name)\n",
        "xml_df.to_csv(('data/train_cdc/train_labels.csv'), index=None)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CS-EfSFJdBDr"
      },
      "source": [
        "## Step 4: Convert training data to TFRecord\n",
        "\n",
        "Ref.\n",
        "https://github.com/EdjeElectronics/TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10/blob/master/generate_tfrecord.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yIFZF2rHyXdO"
      },
      "source": [
        "from os import chdir\n",
        "chdir(\"/content/drive/My Drive/models/research/\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Khh47YPGUN6A"
      },
      "source": [
        "# TO-DO replace this with label map\n",
        "def class_text_to_int(row_label):\n",
        "    if row_label == 'aquarium':#水族箱\n",
        "        return 1\n",
        "    elif row_label == 'bottle':#瓶瓶罐罐、廢電瓶瓶罐\n",
        "        return 2\n",
        "    elif row_label == 'bowl':#碗、盆\n",
        "        return 3\n",
        "    elif row_label == 'box':#盒子\n",
        "        return 4\n",
        "    elif row_label == 'bucket':#桶子\n",
        "        return 5\n",
        "    elif row_label == 'plastic_bag':#塑膠袋、帆布\n",
        "        return 6\n",
        "    if row_label == 'plate':#盤\n",
        "        return 7\n",
        "    elif row_label == 'styrofoam':#保麗龍\n",
        "        return 8\n",
        "    elif row_label == 'tire':#廢輪胎\n",
        "        return 9\n",
        "    elif row_label == 'toilet':#廢馬桶\n",
        "        return 10\n",
        "    elif row_label == 'tub':#浴缸\n",
        "        return 11\n",
        "    elif row_label == 'washing_machine':#洗衣槽\n",
        "        return 12\n",
        "    elif row_label == 'water_tower':#水塔\n",
        "        return 13    \n",
        "    else:\n",
        "        None"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "erIutBmLd4C0"
      },
      "source": [
        "def split(df, group):\n",
        "    data = namedtuple('data', ['filename', 'object'])\n",
        "    gb = df.groupby(group)\n",
        "    return [data(filename, gb.get_group(x)) for filename, x in zip(gb.groups.keys(), gb.groups)]\n",
        "\n",
        "\n",
        "def create_tf_example(group, path):\n",
        "    with tf.io.gfile.GFile(os.path.join(path, '{}'.format(group.filename)), 'rb') as fid:\n",
        "        encoded_jpg = fid.read()\n",
        "    encoded_jpg_io = io.BytesIO(encoded_jpg)\n",
        "    image = Image.open(encoded_jpg_io)\n",
        "    width, height = image.size\n",
        "\n",
        "    filename = group.filename.encode('utf8')\n",
        "    image_format = b'jpg'\n",
        "    xmins = []\n",
        "    xmaxs = []\n",
        "    ymins = []\n",
        "    ymaxs = []\n",
        "    classes_text = []\n",
        "    classes = []\n",
        "\n",
        "    for index, row in group.object.iterrows():\n",
        "        xmins.append(row['xmin'] / width)\n",
        "        xmaxs.append(row['xmax'] / width)\n",
        "        ymins.append(row['ymin'] / height)\n",
        "        ymaxs.append(row['ymax'] / height)\n",
        "        classes_text.append(row['class'].encode('utf8'))\n",
        "        classes.append(class_text_to_int(row['class']))\n",
        "\n",
        "    tf_example = tf.train.Example(features=tf.train.Features(feature={\n",
        "        'image/height': dataset_util.int64_feature(height),\n",
        "        'image/width': dataset_util.int64_feature(width),\n",
        "        'image/filename': dataset_util.bytes_feature(filename),\n",
        "        'image/source_id': dataset_util.bytes_feature(filename),\n",
        "        'image/encoded': dataset_util.bytes_feature(encoded_jpg),\n",
        "        'image/format': dataset_util.bytes_feature(image_format),\n",
        "        'image/object/bbox/xmin': dataset_util.float_list_feature(xmins),\n",
        "        'image/object/bbox/xmax': dataset_util.float_list_feature(xmaxs),\n",
        "        'image/object/bbox/ymin': dataset_util.float_list_feature(ymins),\n",
        "        'image/object/bbox/ymax': dataset_util.float_list_feature(ymaxs),\n",
        "        'image/object/class/text': dataset_util.bytes_list_feature(classes_text),\n",
        "        'image/object/class/label': dataset_util.int64_list_feature(classes),\n",
        "    }))\n",
        "    return tf_example\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y1l4ZEqVVvEu"
      },
      "source": [
        "```\n",
        "Usage:\n",
        "  # From tensorflow/models/\n",
        "  # Create train data:\n",
        "  python generate_tfrecord.py --csv_input=images/train_labels.csv --image_dir=images/train --output_path=train.record\n",
        "  # Create test data:\n",
        "  python generate_tfrecord.py --csv_input=images/test_labels.csv  --image_dir=images/test --output_path=test.record\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_OgD6lZXXJ4V"
      },
      "source": [
        "!ls data/train_cdc/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "45sxyiPZVfYA"
      },
      "source": [
        "output_path = \"data/tfrecords/mbsh_train.tfrecord\"\n",
        "csv_path = \"data/train_cdc/train_labels.csv\"\n",
        "image_dir = \"data/train_cdc/train_images\"\n",
        "\n",
        "writer = tf.io.TFRecordWriter(output_path)\n",
        "examples = pd.read_csv(csv_path)\n",
        "grouped = split(examples, 'filename')\n",
        "for group in grouped:\n",
        "    tf_example = create_tf_example(group, image_dir)\n",
        "    writer.write(tf_example.SerializeToString())\n",
        "writer.close()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k7h9yS9eeDEF"
      },
      "source": [
        "!ls -l data/tfrecords/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ESMQst-EjI9f"
      },
      "source": [
        "# Part 3: Preparation of Object Detection model "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0vqV_X9Fl6DX"
      },
      "source": [
        "## Step 1: Create Label map"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Efer29fcl5bW"
      },
      "source": [
        "!cp object_detection/data/pet_label_map.pbtxt object_detection/data/mbsh_label_map.pbtxt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vgmtff7imEQG"
      },
      "source": [
        "## Step 2: Edit Label map\n",
        "```\n",
        "item {\n",
        "  id: 1\n",
        "  name: 'aquarium'\n",
        "}\n",
        "item {\n",
        "  id: 2\n",
        "  name: 'bottle'\n",
        "}\n",
        "item {\n",
        "  id: 3\n",
        "  name: 'bowl'\n",
        "}\n",
        "item {\n",
        "  id: 4\n",
        "  name: 'box'\n",
        "}\n",
        "item {\n",
        "  id: 5\n",
        "  name: 'bucket'\n",
        "}\n",
        "item {\n",
        "  id: 6\n",
        "  name: 'plastic_bag'\n",
        "}\n",
        "item {\n",
        "  id: 7\n",
        "  name: 'plate'\n",
        "}\n",
        "item {\n",
        "  id: 8\n",
        "  name: 'Styrofoam'\n",
        "}\n",
        "item {\n",
        "  id: 9\n",
        "  name: 'tire'\n",
        "}\n",
        "item {\n",
        "  id: 10\n",
        "  name: 'toilet'\n",
        "}\n",
        "item {\n",
        "  id: 11\n",
        "  name: 'tub'\n",
        "}\n",
        "item {\n",
        "  id: 12\n",
        "  name: 'washing_machine'\n",
        "}\n",
        "item {\n",
        "  id: 13\n",
        "  name: 'water_tower'\n",
        "}\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qkP2msULmGNz"
      },
      "source": [
        "!ls object_detection/data/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "12PFS73amTn5"
      },
      "source": [
        "## Step 3: Configure pipeline\n",
        "https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/configuring_jobs.md\n",
        "```\n",
        "#line 3:\n",
        "    num_classes: 13\n",
        "#line 134:\n",
        "    batch_size: 4\n",
        "#151:\n",
        "    learning_rate_base: 0.008\n",
        "    total_steps: 100000\n",
        "#line 161:\n",
        "      fine_tune_checkpoint: \"efficientdet_d0_coco17_tpu-32/checkpoint/ckpt-0\"\n",
        "#line 162:\n",
        "        num_steps: 10000\n",
        "#line 167:\n",
        "          fine_tune_checkpoint_type: \"detection\"\n",
        "#line 172:\n",
        "        label_map_path: \"object_detection/data/mbsh_label_map.pbtxt\"\n",
        "#line 174:\n",
        "        input_path: \"data/tfrecords/mbsh_train.tfrecord\"\n",
        "#\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GVqiYt1zmZTp"
      },
      "source": [
        "!cp efficientdet_d0_coco17_tpu-32/pipeline.config data/mbsh_pipeline.config"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XNQLEaEioHRJ"
      },
      "source": [
        "!ls data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ksi9mnkvoMPC"
      },
      "source": [
        "# Part 4: IPO-P: Training (about 7-8 hours)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W170xVznoS8A"
      },
      "source": [
        "!python object_detection/model_main_tf2.py \\\n",
        "--alsologtostderr \\\n",
        "--pipeline_config_path=data/mbsh_pipeline.config \\\n",
        "--model_dir=model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WiIfHSl-u47_"
      },
      "source": [
        "# Part 5: IPO-P: Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uL0ASTu4w_4i"
      },
      "source": [
        "## Step 1: Setup "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QJq2psu-u1Zg"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import io\n",
        "import os\n",
        "import pathlib\n",
        "import random\n",
        "import scipy.misc\n",
        "import numpy as np\n",
        "from six import BytesIO\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "\n",
        "from object_detection.utils import label_map_util\n",
        "from object_detection.utils import config_util\n",
        "from object_detection.utils import visualization_utils as viz_utils\n",
        "from object_detection.builders import model_builder\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qaAcdl9zvYrM"
      },
      "source": [
        "def load_image_into_numpy_array(path):\n",
        "  #Load an image from file into a numpy array.\n",
        "  img_data = tf.io.gfile.GFile(path, 'rb').read()\n",
        "  image = Image.open(BytesIO(img_data))\n",
        "  image = image.convert(\"RGB\")\n",
        "  (im_width, im_height) = image.size\n",
        "  return np.array(image.getdata()).reshape(\n",
        "      (im_height, im_width, 3)).astype(np.uint8)\n",
        "\n",
        "def get_keypoint_tuples(eval_config):\n",
        "  \"\"\"Return a tuple list of keypoint edges from the eval config.\n",
        "  \n",
        "  Args:\n",
        "    eval_config: an eval config containing the keypoint edges\n",
        "  \n",
        "  Returns:\n",
        "    a list of edge tuples, each in the format (start, end)\n",
        "  \"\"\"\n",
        "  tuple_list = []\n",
        "  kp_list = eval_config.keypoint_edge\n",
        "  for edge in kp_list:\n",
        "    tuple_list.append((edge.start, edge.end))\n",
        "  return tuple_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HgTfLDxowx2d"
      },
      "source": [
        "## Step 2: COnfigure pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OGTCGzj2vk5V"
      },
      "source": [
        "import os\n",
        "pipeline_config = 'data/mbsh_pipeline.config'\n",
        "model_dir = 'model''\n",
        "\n",
        "# Load pipeline config and build a detection model\n",
        "configs = config_util.get_configs_from_pipeline_file(pipeline_config)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uYErlhlJvm1b"
      },
      "source": [
        "def get_model_detection_function(model):\n",
        "  \"\"\"Get a tf.function for detection.\"\"\"\n",
        "  @tf.function\n",
        "  def detect_fn(image):\n",
        "    \"\"\"Detect objects in image.\"\"\"\n",
        "    image, shapes = model.preprocess(image)\n",
        "    prediction_dict = model.predict(image, shapes)\n",
        "    detections = model.postprocess(prediction_dict, shapes)\n",
        "    return detections, prediction_dict, tf.reshape(shapes, [-1])\n",
        "\n",
        "  return detect_fn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-X6llZDSvqEO"
      },
      "source": [
        "model_config = configs['model']\n",
        "detection_model = model_builder.build(model_config=model_config, is_training=False)\n",
        "detect_fn = get_model_detection_function(detection_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IlizxAsUvrrH"
      },
      "source": [
        "# Restore checkpoint\n",
        "ckpt = tf.compat.v2.train.Checkpoint(model=detection_model)\n",
        "ckpt.restore(os.path.join(model_dir, 'ckpt-xxx')).expect_partial()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sCyK4XjdvtD_"
      },
      "source": [
        "label_map_path = configs['eval_input_config'].label_map_path\n",
        "label_map = label_map_util.load_labelmap(label_map_path)\n",
        "categories = label_map_util.convert_label_map_to_categories(\n",
        "    label_map,\n",
        "    max_num_classes=label_map_util.get_max_label_map_index(label_map),\n",
        "    use_display_name=True)\n",
        "category_index = label_map_util.create_category_index(categories)\n",
        "label_map_dict = label_map_util.get_label_map_dict(label_map, use_display_name=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EmImE3F5w0LU"
      },
      "source": [
        "## Step 3: Predict with trained model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9in9b7MywSeY"
      },
      "source": [
        "import os\n",
        "import glob\n",
        "import pandas as pd\n",
        "Threshold = 0.3\n",
        "classname = ['Nan', 'aquarium', 'bottle', 'bowl', 'box', 'bucket', 'plastic_bag', \n",
        "             'plate', 'styrofoam', 'tire', 'toilet', 'tub', 'washing_machine',\n",
        "             'water_tower']\n",
        "label_id_offset = 1\n",
        "files = sorted(glob.glob(data/train_cdc/train_images/*.jpg'))\n",
        "blist = []\n",
        "for img_file in files:\n",
        "  fname = os.path.basename(img_file)\n",
        "  print(f\"file:{fname} \", end=\"\")\n",
        "  image_np = load_image_into_numpy_array(img_file)\n",
        "  width  = image_np.shape[1]\n",
        "  height = image_np.shape[0]\n",
        "\n",
        "\n",
        "  input_tensor = tf.convert_to_tensor(np.expand_dims(image_np, 0), dtype=tf.float32)\n",
        "  detections, predictions_dict, shapes = detect_fn(input_tensor)\n",
        "\n",
        "  scores  =detections['detection_scores'][0].numpy()\n",
        "  label_ids=detections['detection_classes'][0].numpy().astype(int) + label_id_offset\n",
        "  boxes    =detections['detection_boxes'][0].numpy()\n",
        "\n",
        "  bcount = 0;\n",
        "  for score in list(scores):\n",
        "    if score < Threshold:\n",
        "      break\n",
        "    bcount += 1\n",
        "  if bcount==0 and scores[0] >0.15:\n",
        "    bcount = 1\n",
        "  print(f\" count={bcount}\")\n",
        "  \n",
        "  for i in range(bcount):\n",
        "    score = scores[i]\n",
        "    label_id = label_ids[i].astype(int)\n",
        "    label_name = classname[label_id]\n",
        "    box = boxes[i]\n",
        "    xmin = round(box[0]*width)\n",
        "    xmax = round(box[2]*width)\n",
        "    ymin = round(box[1]*height)\n",
        "    ymax = round(box[3]*height)\n",
        "    record = (fname, width, height, label_name, xmin, ymin, xmax, ymax)\n",
        "    blist.append(record)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GQUn6BvXFwbD"
      },
      "source": [
        "## Step 4:IPO-O: output result\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p_keZfENFzwz"
      },
      "source": [
        "column_name = [\"filename\", \"width\", \"height\", \"class\", \"xmin\", \"ymin\", \"xmax\", \"ymax\"]\n",
        "df = pd.DataFrame(blist, columns=column_name)\n",
        "df.to_csv(('data/labels_train_hat.csv'), index=None)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}