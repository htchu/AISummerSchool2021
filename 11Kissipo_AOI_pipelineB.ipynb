{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "AOI2_Ex1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vpfvx3zSO-je"
      },
      "source": [
        "<table width=\"100%\" border=\"3\">\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <td ><img src=\"https://aidea-web.tw/images/web/logo_white.png\" alt=\"Aidea\" width=\"400\"/></td>\n",
        "      <td align='left'><h1>Exercise 1: AOI full pipeline </h1></td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZOuhb2IiDVpm"
      },
      "source": [
        "# (2): AOI full pipeline\n",
        "* single CNN model\n",
        "* ImageDataGenerator\n",
        "* ModelCheckpoint\n",
        "* EarlyStopping\n",
        "* Submit results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bXEzgNlpP_sv"
      },
      "source": [
        "## Step 1: Load the dataset from google drive\n",
        "https://drive.google.com/file/d/1QXygjos-6UZKrHNsR0as5jhlQU4JK4R9/view?usp=sharing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7VE-8D4WP-zd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d28e442d-7ea4-4069-cbed-cf57266af4ba"
      },
      "source": [
        "from google_drive_downloader import GoogleDriveDownloader\n",
        "GoogleDriveDownloader.download_file_from_google_drive(file_id='1QXygjos-6UZKrHNsR0as5jhlQU4JK4R9',dest_path='./content', unzip=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading 1QXygjos-6UZKrHNsR0as5jhlQU4JK4R9 into ./content... Done.\n",
            "Unzipping...Done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kHlgUk9qQLRu"
      },
      "source": [
        "## Step 2: Import python libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OCJBD9x1Bv8n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4cc4e17-3d37-450f-cd6e-5b983d087178"
      },
      "source": [
        "import tensorflow as tf\n",
        "#tf.config.experimental.set_memory_growth(tf.config.list_physical_devices('GPU')[0], True)\n",
        "print(tf.__version__)\n",
        "print(tf.config.list_physical_devices('GPU'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.4.1\n",
            "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gl5ZMXU3S_rH"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cLyRMQLrFUpY"
      },
      "source": [
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, Activation, Flatten\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.layers import Dropout, Flatten, Activation\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
        "from tensorflow.keras.optimizers import Adam,SGD,Adagrad,Adadelta,RMSprop"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4TXVhSDQQXXO"
      },
      "source": [
        "## Step 3: read the training set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pL3o453NU26h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18b5237c-a7a7-4d66-a831-c8ca207d902a"
      },
      "source": [
        "import pandas as pd\n",
        "df_train = pd.read_csv(\"train.csv\",dtype=str )\n",
        "print(df_train.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(5056, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tuDemzs5VKFk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "e01bf515-a911-494d-e670-e041bacc524f"
      },
      "source": [
        "df_train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>train_00000.jpg</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>train_00001.jpg</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>train_00002.jpg</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>train_00003.jpg</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>train_00004.jpg</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                ID Label\n",
              "0  train_00000.jpg     0\n",
              "1  train_00001.jpg     1\n",
              "2  train_00002.jpg     1\n",
              "3  train_00003.jpg     5\n",
              "4  train_00004.jpg     5"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-cVo6Gq4FApt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "34ca75a4-81f3-47ee-f4f3-290d01454974"
      },
      "source": [
        "train_files = df_train.iloc[:,0].values\n",
        "train_labels = df_train.iloc[:,1].values\n",
        "print(train_labels[:10])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['0' '1' '1' '5' '5' '5' '3' '0' '3' '5']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PbZydP89TWuN"
      },
      "source": [
        "## Step 4: Show statistics of training images "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TtQV07_cFK7Y",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "outputId": "8188896b-1af3-4ceb-c1a5-2ac4f6f9fa49"
      },
      "source": [
        "import seaborn as sns\n",
        "g = sns.countplot(train_labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
            "  FutureWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8YKcKTBabLig"
      },
      "source": [
        "num_classes=6"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9VfcJvPCTwjX"
      },
      "source": [
        "## Step 5: Choose one of CNN models \n",
        "* DenseNet121(...): Instantiates the Densenet121 architecture.\n",
        "* DenseNet169(...): Instantiates the Densenet169 architecture.\n",
        "* DenseNet201(...): Instantiates the Densenet201 architecture.\n",
        "* InceptionResNetV2(...): Instantiates the Inception-ResNet v2 architecture.\n",
        "* InceptionV3(...): Instantiates the Inception v3 architecture.\n",
        "* MobileNet(...): Instantiates the MobileNet architecture.\n",
        "* MobileNetV2(...): Instantiates the MobileNetV2 architecture.\n",
        "* NASNetLarge(...): Instantiates a NASNet model in ImageNet mode.\n",
        "* NASNetMobile(...): Instantiates a Mobile NASNet model in ImageNet mode.\n",
        "* ResNet101(...): Instantiates the ResNet101 architecture.\n",
        "* ResNet101V2(...): Instantiates the ResNet101V2 architecture.\n",
        "* ResNet152(...): Instantiates the ResNet152 architecture.\n",
        "* ResNet152V2(...): Instantiates the ResNet152V2 architecture.\n",
        "* ResNet50(...): Instantiates the ResNet50 architecture.\n",
        "* ResNet50V2(...): Instantiates the ResNet50V2 architecture.\n",
        "* VGG16(...): Instantiates the VGG16 model.\n",
        "* VGG19(...): Instantiates the VGG19 architecture.\n",
        "* Xception(...): Instantiates the Xception architecture.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ndL1lGGwEsOM"
      },
      "source": [
        "from tensorflow.keras.applications import InceptionV3\n",
        "model = InceptionV3(include_top = True, input_shape=(299,299,3), weights=None, classes=num_classes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B1ZBp4fUriRS",
        "outputId": "9ced6986-c01a-4489-ee23-0e8c4f280468"
      },
      "source": [
        "from tensorflow.keras.applications import EfficientNetB1\n",
        "base_model = EfficientNetB1(include_top = False, input_shape=(299,299,3), weights=\"imagenet\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb1_notop.h5\n",
            "27025408/27018416 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2wbxoTBOr0wU"
      },
      "source": [
        "model = models.Sequential()\n",
        "model.add(base_model)\n",
        "model.add(layers.GlobalMaxPooling2D(name=\"gap\"))\n",
        "#avoid overfitting\n",
        "model.add(layers.Dropout(rate=0.2, name=\"dropout_out\"))\n",
        "# Set NUMBER_OF_CLASSES to the number of your final predictions.\n",
        "model.add(layers.Dense(num_classes, activation=\"softmax\", name=\"fc_out\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MARzRhyY49NB"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xQgZdcYwUVqG"
      },
      "source": [
        "## Step 6: Instancing an ImageDataGenerator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2FglrsMfXMBC"
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "#from tensorflow.keras.applications.xception import preprocess_input\n",
        "from tensorflow.keras.applications.efficientnet import preprocess_input\n",
        "img_gen = ImageDataGenerator(preprocessing_function=preprocess_input)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s5oRwE1UUiFf"
      },
      "source": [
        "## Step 7: Set up a train_generator with flow_from_dataframe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gIAZ72MWSzmb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe5c621b-c3c0-4aed-916e-4fb72bba20c7"
      },
      "source": [
        "train_generator = img_gen.flow_from_dataframe(dataframe=df_train,\n",
        "            directory=\"train_images\",\n",
        "            x_col=\"ID\",\n",
        "            y_col=\"Label\",\n",
        "            subset=None,\n",
        "            batch_size=8,\n",
        "            shuffle=False,\n",
        "            class_mode=\"categorical\",\n",
        "            color_mode=\"rgb\",\n",
        "            target_size=(299,299))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 5056 validated image filenames belonging to 6 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CzqOQhERYbGs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4303798e-0cb4-47e6-c3b2-17495a4f34fb"
      },
      "source": [
        "train_generator.class_indices"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'0': 0, '1': 1, '2': 2, '3': 3, '4': 4, '5': 5}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n3FgxCjpVG3H"
      },
      "source": [
        "## Step 8: step_size_train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fu7E0m3ucZCJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc4c9c1e-5a12-4ed3-9340-af94df5d4f7d"
      },
      "source": [
        "if train_generator.n % train_generator.batch_size ==0:\n",
        "  step_size_train=train_generator.n//train_generator.batch_size\n",
        "else:\n",
        "  step_size_train=train_generator.n//train_generator.batch_size + 1\n",
        "print(step_size_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "632\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0cggn0VQVJUa"
      },
      "source": [
        "## Step 9: ModelCheckpoint"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VgdfV2r-K7Hj"
      },
      "source": [
        "# Include the epoch in the file name (uses `str.format`)\n",
        "import os\n",
        "checkpoint_path = \"training_cp/cp-{epoch:03d}.ckpt\"\n",
        "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
        "# Create a callback that saves the model's weights \n",
        "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path , save_weights_only=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GUSuhwUzVPVH"
      },
      "source": [
        "## Step 10: EarlyStopping"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MeWdoKDPLEoG"
      },
      "source": [
        "# Create a callback that stop the model \n",
        "es_callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_s2HkH4iVWJp"
      },
      "source": [
        "## Step 11: Compile model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ILyWZe8G1cX"
      },
      "source": [
        "#compile model using accuracy to measure model performance\n",
        "from tensorflow.keras import optimizers\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "            optimizer=optimizers.Adam(lr=3e-3),\n",
        "            metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AjzOG579Vcxx"
      },
      "source": [
        "## Step 12: Train model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "31K9h5ePJ5-O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad5a7657-df1a-45cd-baa8-61eb0e0527c4"
      },
      "source": [
        "hist = model.fit(train_generator, steps_per_epoch=step_size_train, callbacks=[cp_callback, es_callback], epochs=100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "607/632 [===========================>..] - ETA: 5s - loss: 2.2839 - accuracy: 0.6532"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XKKEeCDJVufY"
      },
      "source": [
        "## Step 13: Evaluate saved checkpoints"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-hzIeF9RMBHg"
      },
      "source": [
        "##checkpoint 1\n",
        "model.load_weights(\"training_cp/cp-020.ckpt\")\n",
        "train_generator.reset()\n",
        "model.evaluate_generator(generator=train_generator, steps=step_size_train, verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "13RQaTOPXz8Z"
      },
      "source": [
        "##checkpoint 2\n",
        "model.load_weights(\"training_cp/cp-019.ckpt\")\n",
        "train_generator.reset()\n",
        "model.evaluate_generator(generator=train_generator, steps=step_size_train, verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zxpAhXHWX0lN"
      },
      "source": [
        "##checkpoint 3\n",
        "model.load_weights(\"training_cp/cp-018.ckpt\")\n",
        "train_generator.reset()\n",
        "model.evaluate_generator(generator=train_generator, steps=step_size_train, verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rJ9oNZwlYCLk"
      },
      "source": [
        "## Step 14: Save the trained model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ZuxezvUMV0W"
      },
      "source": [
        "model.load_weights(\"training_cp/cp-020.ckpt\")\n",
        "model.save(\"AOI-InceptionV3-0128.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E4Kdl8aBYWpQ"
      },
      "source": [
        "## Step 15: Check training results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "snwxn3uEidj8"
      },
      "source": [
        "#y_predictions = model.predict(X_train, batch_size=20)\n",
        "train_generator.reset()\n",
        "y_predictions = model.predict_generator(generator=train_generator, steps=step_size_train, verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-3LFfE8bPjOD"
      },
      "source": [
        "print(y_predictions[:2])\n",
        "type(y_predictions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Apz1b0obPql5"
      },
      "source": [
        "predicts = np.argmax(y_predictions,axis=1)\n",
        "print(predicts[0:10])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U8KJfM2AVNIg"
      },
      "source": [
        "labels = train_labels.astype(int)\n",
        "print(labels[:10])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0K0X0oUSZMCl"
      },
      "source": [
        "## Step 16: Analyze training results\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aZ3NL3iNVYFy"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "confusion=confusion_matrix(labels, predicts)\n",
        "print(confusion)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AEwJyegWXWKW"
      },
      "source": [
        "train_num= 2528\n",
        "overkill= []\n",
        "underkill = []\n",
        "for i in range(train_num):\n",
        "  if labels[i] == 0 and predicts[i] !=0:\n",
        "    overkill.append(i)\n",
        "  if labels[i] != 0 and predicts[i] ==0:\n",
        "    underkill.append(i)\n",
        "print('# of overkill= {}; # of underkill= {} '.format(len(overkill), len(underkill)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oB5cwshcZdRo"
      },
      "source": [
        "## Step 17: Load the test set "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gH3N656tHvVF"
      },
      "source": [
        "df_test = pd.read_csv(\"test.csv\",dtype=str)\n",
        "print(df_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hukndpFCnTBM"
      },
      "source": [
        "df_test.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "26sEKiQYH2sr"
      },
      "source": [
        "test_files  = df_test.iloc[:,0].values\n",
        "test_labels = df_test.iloc[:,1].values\n",
        "print(test_labels[:10])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_BLG-wtcZvze"
      },
      "source": [
        "## Step 18: Set up a test_generator with flow_from_dataframe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rjzR0cmDjPT-"
      },
      "source": [
        "test_generator = img_gen.flow_from_dataframe(dataframe=df_test,\n",
        "            directory=\"test_images\",\n",
        "            x_col=\"ID\",\n",
        "            y_col=\"Label\",\n",
        "            batch_size=32,\n",
        "            shuffle=False,\n",
        "            class_mode=None,\n",
        "            target_size=(299,299))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WkKvBn2paAYi"
      },
      "source": [
        "## Step 19: step_size_test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c3z-YfOEn0UF"
      },
      "source": [
        "if test_generator.n % test_generator.batch_size ==0:\n",
        "  step_size_test=test_generator.n//test_generator.batch_size\n",
        "else:\n",
        "  step_size_test=test_generator.n//test_generator.batch_size + 1\n",
        "print(step_size_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wzBR-D2-abER"
      },
      "source": [
        "## Step 20: Check test results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "chRywd4OnsFK"
      },
      "source": [
        "#y_predictions = model.predict(X_train, batch_size=20)\n",
        "test_generator.reset()\n",
        "y_predictions = model.predict_generator(generator=test_generator, steps=step_size_test,verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9UyO5HWMkRl4"
      },
      "source": [
        "import numpy as np\n",
        "predicts=np.argmax(y_predictions,axis=1)\n",
        "predicts[:10]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Af7iNMQAlQZH"
      },
      "source": [
        "len(predicts)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iqkymIOfaeg1"
      },
      "source": [
        "## Step 21: Output test results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0sXBA6kypHZd"
      },
      "source": [
        "df_out = pd.DataFrame(df_test)\n",
        "df_out.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z5sYBeoVIAKA"
      },
      "source": [
        "df_out['Label'] = predicts\n",
        "df_out.to_csv(\"0128-aoi.csv\", index=False)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}